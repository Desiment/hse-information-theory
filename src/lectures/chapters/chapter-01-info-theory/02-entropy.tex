% !TeX root = ../../notes.tex
% !TeX spellcheck = ru-RU
% !TeX encoding = UTF-8 Unicode
% !BIB program = biber
% LTeX: language=ru-RU
% LTeX: enablePickyRules=true
% Copyright (c) 2026 Михаил Михайлов
%
% This work is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0
% International License. To view a copy of this license, visit:
% http://creativecommons.org/licenses/by-nc-sa/4.0/
%
% You are free to:
%   Share - copy and redistribute the material in any medium or format
%   Adapt - remix, transform, and build upon the material
%
% Under the following terms:
%   Attribution - You must give appropriate credit, provide a link to the license,
%                 and indicate if changes were made.
%   NonCommercial - You may not use the material for commercial purposes.
%   ShareAlike - If you remix, transform, or build upon the material, you must
%                distribute your contributions under the same license as the original.
%
% See the LICENSE file in the repository root for full license text.


\section{Энтропия}
\localtableofcontents

\vspace{3ex}

Ранее мы рассматривали собственную информацию отдельных событий. Теперь перейдём к полным системам событий, описывающим исходы некоторого случайного опыта/эксперимента.

\subsection{Понятие об опыте. Энтропия Шеннона}
\begin{definition*}[Случайный опыт]
Под случайным опытом понимается конечная система непересекающихся событий
\[
\mathcal{A} = \set{A_1, \dots, A_n}, \quad A_i \cap A_j = \varnothing, \ i \neq j, \quad \bigsqcup_{i=1}^n A_i = \Omega,
\]
где \(\Omega\) --- пространство элементарных исходов, \(\P(A_i) > 0, i = 1, \ldots n \). События $A_i$ называются результатами или исходами такого опыта.
\end{definition*}
\begin{remark}
    Данное определение не является конвенциональным, хотя встречается в литературе. Мы используем его только в рамках данного курса, чтобы не писать каждый раз \enquote{полная система событий}.
\end{remark}


Для полной системы событий естественно определить следующую величину:
\begin{definition}[Энтропия случайного опыта]
	\emph{Энтропией} случайного опыта \(\mathcal{A} = \set{A_1, \dots, A_n}\) называется средняя собственная информация результата опыта:
\[
	\H_m(\mathcal{A}) = \sum_{i=1}^n \P(A_i) \cdot \I_m(A_i) = - \sum_{i=1}^k p_i \log_m p_i.
\]
\end{definition}
\begin{remark}
	Как и ранее, если нижний индекс опускается, подразумевается логарифм по основанию 2, \(\H(\cdot) = \H_2(\cdot)\)
\end{remark}

\begin{example}[Честная монета]
Случайный опыт \(\mathcal{A} = \{O, R\}\), \(\P(O) = \P(R) = 0.5\):
\[
	\H(\mathcal{A}) = - (0.5 \log_2 0.5 + 0.5 \log_2 0.5) = 1 \text{ бит}.
\]
\end{example}

\begin{example}[Нечестная монета]
Случайный опыт \(\mathcal{A} = \{O, R\}\), \(\P(O) = 0.8\), \(\P(R) = 0.2\):
\[
\H(\mathcal{A}) = - (0.8 \log_2 0.8 + 0.2 \log_2 0.2) \approx 0.72 \text{ бита}.
\]
\end{example}

\begin{notation}
	\(\H_m(p_1, \ldots, p_n)\) будет обозначать энтропию Шеннона для некоторого опыта, результаты которого имеют вероятности $p_1, \ldots, p_n$.	
\end{notation}
\subsection{Неравенство Гиббса. Оценки энтропии}

\begin{Lemma}[Неравенство Гиббса]
    \label{lm:gibbs-ineq}
    Для любых двух наборов чисел $p_1, \ldots, p_n$ и $q_1, \ldots, q_n$ в полуинтервале $(0; 1]$, таких что:
	\[
        \sum_{i = 1}^{n} p_i = 1, \quad
        \sum_{i = 1}^{n} q_i \leq 1,
	\]
    и для любого вещественного $m > 1$ выполнено неравенство:
    \begin{equation}
        \label{eq:gibbs-ineq}
       -\sum_{i = 1}^{n} p_i \log_m p_i  \leq  -\sum_{i = 1}^{n} p_i \log_m q_i
    \end{equation}
    Причем равенство достигается тогда и только тогда, когда $q_i = p_i$ для всех $i = 1,\ldots, n$
\end{Lemma}
\begin{proof}
    Не умаляя общности $m = 2$. Перепишем неравенство \eqref{eq:gibbs-ineq} в следующем виде:
    \[
        \sum_{i = 1}^{n} p_i \log \frac{q_i}{p_i} \leq 0
    \]
    Дальше, поскольку $\log$ --- вогнутая функция, то по неравенству Йенсена имеем:
    \[
        \sum_{i = 1}^{n} p_i \log \frac{q_i}{p_i} \leq \log\mleft(\sum_{i = 1}^{n} p_i \cdot \frac{q_i}{p_i}\mright) = \log\mleft(\sum_{i = 1}^{n}q_i\mright) \leq \log(1) \leq 0
    \]
	Теперь рассмотрим случай равенства. Из случай равенства в неравенстве Йенсена имеем что:
	\[
		\frac{p_1}{q_1} = \ldots = \frac{p_n}{q_n} = \gamma
	\]
	И значит $\sum p_i = \gamma \sum q_i$. С другой стороны $\sum q_i = 1$ --- это следует из второго неравенства.
\end{proof}
\begin{theorem}[О значениях энтропии]
    Для любых \(p_1, \ldots, p_n \in [0; 1]\) таких что \(\sum_{i = 1}^{n} p_i = 1\) верно что
    \[
        0 \leq \H_m(p_1, \ldots, p_n) \leq \log_m n
    \]
	Причем:
	\begin{itemize}[compact]
		\item Равенство $\H_m(p_1, \ldots, p_n) = 0$ достигается тогда и только тогда, когда  одна из вероятностей $p_i$ равна 1.
		\item Равенство $\H_m(p_1, \ldots, p_n) = \log_m n$ достигается тогда и только тогда, когда все вероятности $p_i = \frac{1}{n}, i = 1,\ldots n$.
	\end{itemize}
\end{theorem}
\begin{proof}
    Не умаляя общности $m = 2$.

    \noindent\fbox{\textit{Нижняя граница.}} Понятно что поскольку $-p\log p \geq 0$ для всякого $p \in [0;1]$\footnote{Здесь и далее, принято соглашение, что $0 \cdot \log 0 = 0$.}, величина $\H$ неотрицательна как сумма неотрицательных величин. Пусть теперь $\H(p_1, \ldots, p_n) = 0$. Понятно тогда что
    \[
        p_1 \log p_1 = \ldots = p_n \log p_n = 0 \quad \Leftrightarrow \quad \forall i = 1, \ldots, n \ p_i \in \set{0, 1}
    \]
    С учетом того что $p_1 + \ldots + p_n = 1$, получаем что ровно одно значение $p_i$  равно 1, все остальные --- 0.

    \noindent\fbox{\textit{Верхняя граница.}} По неравенству Гиббса с $q_i = \frac{1}{n}$:
    \[
        - \sum_{i = 1}^{n} p_i \log p_i \leq -\sum_{i = 1}^{n} p_i \log \frac{1}{n} = -\log\frac{1}{n} \cdot \underbrace{\sum_{i = 1}^{n} p_i}_{1} = \log n
    \]
    Причем, в силу случая равенства в лемме \ref{lm:gibbs-ineq}, равенство достигается только при $p_i = \frac{1}{n}$.
\end{proof}

\subsection*{Приложение. О различных смыслах энтропии}
\addcontentsline{toc}{subsection}{Приложение. О различных смыслах энтропии}
Что на самом деле измеряет энтропия? Довольно часто на этот вопрос дают такой ответ: энтропия --- мера неопределённости. Однако, этот ответ во-первых весьма туманен, а во-вторых слово \emph{неопределённость} само по себе носит не вполне определённый смысл. Конечно, у нас есть интерпретация с точки зрения теории информации: для события $A$ его собственная информация $\I(A)$ это объём/длина сообщения, которым мы бы могли описать, что это событие произошло. В свою очередь энтропия опыта с несколькими исходами --- усреднённое по вероятности значение собственной информации:
\[
	\H(X) = -\sum_{i} p_i \log_2 p_i,
\]
где $p_i$ --- вероятность $i$‑го исхода. Но такая трактовка тоже не до конца ясна: для бинарного события сообщение, фиксирующее его исход, всегда будет иметь размер $1$ бит, независимо от вероятности. Так почему же собственная информация события для нечестного броска монетки будет меньше одного бита (и энтропия тоже)? Тут на помощь приходит асимптотический анализ: оказывается, что если взять достаточно большое число бросков нечестной монеты и выписать в ряд результаты, например
\[
\text{ОРООРРРРРРРОРРРРОРРРРРРР},
\]
то окажется, что если кодировать не каждый символ по отдельности, а, скажем, блоки из трёх символов, то последовательность можно сжать. Причём при самом эффективном сжатии удельная длина символа при росте блока будет пропорциональна $-\log_2$ его вероятности. Это в некотором смысле объясняет, как же информация может быть нецелым числом: в среднем на один символ можно \enquote{экономить} часть бита, хотя отдельный символ требует целого бита.

Однако привязка к теории кодирования несколько неудобна, поскольку ограничивает наши способности к обобщению; в частности, на непрерывный случай. Оказывается, что энтропия имеет физический смысл. В первую очередь, она является прямым аналогом и обобщением термодинамической энтропии. Чтобы понять её суть представим себе следующее. Пускай есть некоторая кристаллическая решетка, находящаяся в состоянии термодинамического равновесия, в частности, имеющая некоторую стабилизированную температуру. Будем считать что пока есть только один параметр --- температура. Тогда значение температуры определяет \textit{макросостояние} системы.  С другой стороны, температура обеспечивается за счет колебаний частиц формирующих решетку; каждая отдельная частица решетки колеблется с частотой из некоторого дискретного набора; полное описание такой системы вида \enquote{частица}--\enquote{частота колебания} составляет \textit{микросостояние} системы. Одному макросостоянию отвечает множество разных микросостояний, реализующих его. Энтропия Больцмана определяется как
\[
	S = k_B \ln W,
\]
где $W$ --- число микросостояний, реализующих данное макросостояние. Однако такое определение корректно для ситуации термодинамического равновесия, когда все микросостояния равновероятны. Обобщение на ситуацию произвольных вероятностей микросостояний было предложено Гиббсом:
\[
	S_{\text{Гиббса}} = -k_B \sum_i p_i \ln p_i,
\]
где $p_i$ --- вероятность $i$-ого микросостояния. При измерении в битах (делении на $k_B\ln 2$) энтропия Гиббса даёт формулу Шеннона:
\[
\H = \frac{S_{\text{Гиббса}}}{k_B\ln 2}.
\]
В этом контексте энтропия Шеннона измеряет \textit{априорный} \enquote{объём} нашего незнания о точном микроскопическом состоянии системы при известных макроскопических параметрах. Чем больше возможных микросостояний (конфигураций) совместимо с нашими наблюдениями, тем выше неопределённость (энтропия) и тем больше информации мы получим, узнав точное состояние системы. Внезапно, эта точка зрения довольно тесно перекликается с теорией вероятности. Мы можем считать, что и \enquote{микросостояния} --- это элементы полной системы событий $\mathcal{A}$, описывающей различные уровни \enquote{энергии}, иначе говоря, различные микросостояния системы. Тогда, с точностью до константы, энтропия Шеннона и энтропия Гиббса совпадают. 

В этом смысле, энтропию можно понимать как меру дезорганизации, сложности или информационной ёмкости системы. Физическая система с низкой энтропией (например, кристаллическая решётка при абсолютном нуле или выстроенный в линию газ) является высокоорганизованной и предсказуемой: зная положение одной молекулы, можно с высокой уверенностью предсказать положение соседней. Сообщение о её состоянии будет коротким. Система с высокой энтропией (газ в равновесии, хаотичная структура) максимально неупорядочена и непредсказуема --- для точного описания её конфигурации потребуется огромное количество информации. Таким образом, физический процесс увеличения термодинамической энтропии в изолированной системе соответствует стиранию различий и переходу к более \enquote{типичному}, а значит, и более вероятному с информационной точки зрения состоянию, которое описывается большим числом бит.

\newpage
\subsection*{Приложение. Неравенство Йенсена}
\addcontentsline{toc}{subsection}{Приложение. Неравенство Йенсена}
\begin{theorem*}[Неравенство Йенсена]
    Пусть $f(x) \colon E \to \R$, $E = \langle a; b \rangle \subset \R$ --- выпуклая функция. Тогда для любых точек $x_1, \ldots, x_n \in E$, и любых чисел $p_1, \ldots, p_n \in (0; 1)$ таких, что $\sum_{i = 1}^{n} p_i = 1$, выполнено неравенство:
    \begin{equation}
        \label{eq:jensen-ineq}
        f\mleft(\sum_{i = 1}^{n}p_ix_i\mright) \geq \sum_{i = 1}^{n} p_i f(x_i)
    \end{equation}
    Причем равенство достигается тогда и только тогда, когда:
    \begin{enumerate}[noitemsep, topsep=0pt, parsep=0pt]
        \item либо все точки $x_i$ равны некоторому $x_0 \in E$;
        \item либо функция $f$ линейна\footnote{Везде и далее более правильно говорить аффинная: т.е. $f(x) = ax + b$ для некоторых $a, b \in \R$.} на некотором отрезке $E'$ содержащем все точки $x_i$.
    \end{enumerate}
\end{theorem*}
\begin{proof}
    Для случая $n = 2$ неравенство \eqref{eq:jensen-ineq} есть определение выпуклой функции. Покажем что, если для каких-то $p_1, p_2 \in (0; 1), p_1 + p_2 = 1$ неравенство обратилось в равенство, то $f$ будет линейна на соответствующем отрезке\footnote{Случай равенства $x_1 = x_2$ в силу его тривиальности}. Не умаляя общности, пусть $x_1 < x_2, p_1 = p, p_2 = 1 - p, p \in (0; 1)$. И пусть:
    \[
        f(px_1 + (1 - p)x_2) = pf(x_1) + (1-p)f(x_2)
    \]
    Рассмотрим функцию
    \[
        g(x) = (x - x_1)\frac{f(x_2) - f(x_1)}{x_2 - x_1}
    \]
    Имеем:
    \begin{enumerate}[noitemsep, topsep=0pt, parsep=0pt]
        \item $g(x)$ линейная функция из $E' = [x_1, x_2]$ в $\R$;
        \item $g(x_1) = f(x_1),\, g(x_2) = f(x_2)$ и для всех точек $x \in E'$  $f(x) \geq g(x)$
        \item $d(x) = f(x) - g(x)$ --- выпуклая функция.
    \end{enumerate}
    Пункты 2 и 3 легко проверить по определению выпуклой функции. Итак, обозначим $x^* = px_1 + (1 - p)x_2 \in E'$. Тогда имеем что $d(x_1) = d(x_2) = d(x^*) = 0$. С другой стороны, если $f(x)$ нелинейна, то $f(x)$ строго больше $g(x)$ хотя бы в одной точке. Не умаляя общности, пусть это точка $\hat{x} \in (x_1; x^*)$. Тогда для некоторого $\lambda \in (0; 1)$ верно что $x^* =\lambda \hat{x} + (1-\lambda)x_2$. Но тогда, в силу выпуклости $d$:
    $$
            0 = d(x^*) = d(\lambda \hat{x} + (1-\lambda)x_2) \leq \lambda d(\hat{x}) + (1 - \lambda) d(x_2) = \lambda \cdot d(\hat{x}) > 0\,.
    $$
    Противоречие и значит $f(x) = g(x)$ для всех $x \in E'$.

    Покажем теперь неравенство для произвольного $n$. Для этого воспользуемся математической индукцией с уже доказанной базой $n = 2$. Считая, что неравенство доказано для любых наборов точек размера $n-1$,  рассмотрим произвольный набор из $n$ точек $x_1 \leq x_2 \leq \ldots \leq x_n$. Положим
    \begin{align*}
        & y_1 = x_1, \quad q_1 = p_1 \\
        & y_2 = \frac{p_2x_2 + \ldots + p_nx_n}{p_2 + \ldots + p_n} , \quad q_2 = 1 - q_1 \\
    \end{align*}
    По определению выпуклости имеем что
    \begin{align*}
        f\mleft(\sum_{i = 1}^{n}p_ix_i\mright) = f(q_1y_1 + q_2y_2) \geq q_1f(y_1) + q_2f(y_2) = p_1f(x_1) + &(p_2 + \ldots + p_n) f\mleft(\frac{1}{ (p_2 + \ldots + p_n)}\sum_{i = 2}^{n} p_i x_i\mright) \shortintertext{Применяя ко второму слагаемому индукционое предположение} \geq p_1f(x_1) + &\sum_{i = 2}^{n}p_i f\mleft( x_i\mright) = \sum_{i = 1}^{n} p_i f(x_i)
    \end{align*}
    Что и требовалось доказать. Случай равенства разбирается аналогично $n = 2$ --- все неравенства  выше обращаются в равенства и из этого получается что $f$ линейна на $[x_1, x_n]$.
\end{proof}

\newpage
\section{Условная и совместная энтропия}
\localtableofcontents

\subsection{Совместная и условная собственная информация}

В реальных задачах часто приходится иметь дело не с одиночными событиями, а с их комбинациями и зависимостями. Для этого вводятся понятия совместной и условной информации.
\begin{definition}
    Пусть \(A\) и \(B\) --- два события, \(\P(A \cap B) > 0\). Совместной информацией событий $A$ и $B$ называется собственная информация пересечения:
    \[
        \I_m(A, B) = \I_m(A \cap B).
    \]
    Условной информацией события \(A\) при условии события \(B\) называется величина:
    \[
        \I_m(A | B) = -\log \P (A | B).
    \]
\end{definition}
\begin{notation}
	\(\I_m(A_1, \ldots, A_n) = \I_m(A_1 \cap \ldots \cap A_n)\)
\end{notation}
\begin{notation}
    \(\I_m(A | B_1, \ldots, B_n) =  \I_m(A | B_1 \cap \ldots \cap B_n)\)
\end{notation}
\begin{proposition*}
    Пусть \(A\) и \(B\) --- два события, \(\P(A \cap B) > 0\).
    \[
        \I_m(A | B) = \I_m(A) + \I_m(B | A) = \I_m(B) + \I_m(A | B).	
    \]
\end{proposition*}
\begin{proof}
    Не умаляя общности $m = 2$. Распишем по определению:
    \[
        \I(A \cap B) = \log \P(A \cap B) = \log (\P(A) \cdot \P(A | B)) = \log \P(A) + \log \P(A | B) =  \I(B) + \I(A | B)
    \]
\end{proof}


\begin{example}[Два независимых броска монеты]
Пусть \(O_1\) --- событие выпадения орла при первом броске честной монеты, а \(O_2\) --- аналогичное событие для второго броска. Имеем
\[
    \P(O_1) = \P(O_2)=0.5,
\]
причём события независимы. Тогда
\[
    \I(O_1, O_2) = \I(O_1) + \I(O_2) = 1 + 1 = 2 \text{ бита}.
\]
\end{example}

\begin{example}[Зависимые события]
Рассмотрим следующую модель: первый бросок монеты честный, а второй полностью определяется первым. Если в первом броске выпал орёл, то во втором обязательно выпадает решка, и наоборот. Тогда
\[
    \P(O_1)=\P(R_1)=0.5.
\]
Собственная информация первого броска равна \(\I(O_1)=1\) бит, а условная информация второго броска при известном первом исходе равна
\[
    \I(R_2 | O_1) = -\log 1 = 0.
\]
Следовательно,
\[
    \I(R_2 | O_1) = 1 \text{ бит}.
\]
\end{example}

\begin{example}[Последовательность символов]
Пусть источник независимо генерирует символы \(a,b,c\) с вероятностями
\[
    \P(a)=0.5, \quad \P(b)=0.25, \quad \P(c)=0.25.
\]
Для последовательности \(abc\)
\[
    \P(abc)=0.03125, \qquad
    \I(a,b,c) = 5 \text{ бит}.
\]
Если получены только первые два символа,
\[
    \I(a,b) =3 \text{ бита}.
\]
\end{example}

\subsection{Условная энтропия.}
Здесь и далее, речь идет о нескольких опытах сразу. Пусть имеются два опыта
\[
	\mathcal{A} = \set{A_1, \dots, A_{n_a}} = \set{A_{i_a}}_{i = 1}^{n_a}, \quad \mathcal{B} = \set{B_1, \dots, B_{n_b}} = \set{B_{i_b}}_{i_b = 1}^{n_b},
\]
Для простоты обозначений, мы будем считать что с каждым опытом связан свой индекс. В частности, для опыта $\mathcal{A}$ вероятности исходов $\P(A_{i_a}), i_a = 1, \ldots, n_a$ мы будем обозначать за $p_{i_a}$, а для опыта $\mathcal{B}$ --- вероятности $\P(B_{i_b}), i_b = 1, \ldots, n_b$ обозначим за $p_{i_b}$.
\begin{remark}
	Из-за такого злоупотребления обозначениями (abuse of notation), формально запись $p_1$ обозначает непонятно что. Но таких обозначений далее не будет.
\end{remark}
\begin{definition}[Условная энтропия]
	Пусть \(p_{i_b|i_a} = \P(B_{i_b} \mid A_{i_a})\). Условная энтропия опыта \(\mathcal{B}\) относительно опыта~\(\mathcal{A}\) определяется как
\[
	\H_m(\mathcal{B} | \mathcal{A}) 
	= \sum_{i_a=1}^{n_a} \P(A_{i_a}) \sum_{i_b = 1}^{n_b} \P(B_{i_b} | A_{i_a}) \I_m(B_{i_b} | A_{i_a}) 
	= -\sum_{i_a=1}^{n_a} p_{i_a} \sum_{i_b=1}^{n_b} p_{i_b|i_a} \log_m p_{i_b|i_a}.
\]
\end{definition}

\begin{proposition}
	\label{prop:conditional-entropy-estimates}
	Для любых двух опытов $\mathcal{A}$ и $\mathcal{B}$ выполнено:
    \[
        0 \leq \H_m(\mathcal{B}  | \mathcal{A}) \leq \H_m(\mathcal{B})
    \]
	Причем:
	\begin{itemize}[compact]
		\item равенство \(\H_m(\mathcal{B}  | \mathcal{A}) = \H_m(\mathcal{B})\) достигается тогда и только тогда, когда любые два события $A \in \mathcal{A}, B \in \mathcal{B}$ независимы;
		\item равенство \(\H_m(\mathcal{B}  | \mathcal{A}) = 0\) достигается тогда и только тогда, когда для любых событий $A \in \mathcal{A}, B \in \mathcal{B}$, выполнено~$\P(B | A) \in \set{0, 1}$.
	\end{itemize}
\end{proposition}
\begin{proof}
	 Не умаляя общности $m = 2$.

    \noindent\fbox{\textit{Нижняя граница.}} Следует из того что каждое слагаемое неотрицательно. Рассмотрим случай равенства: имеем что
	\[
		\text{Для любых $i_a = 1, \ldots n_a$, $i_b = 1, \ldots, n_b$}\ : \ p_{i_a} p_{i_b|i_a} \log p_{i_b|i_a} = 0
	\]
	Откуда возможны три случая:
	\begin{enumerate}[compact]
		\item $p_{i_a} = 0$;
		\item $p_{i_b | i_a} = 0$;
		\item $\log p_{i_b | i_a} = 0$, т.е. $p_{i_b | i_a} = 1$.
	\end{enumerate}
	Первый случай невозможен по определению опыта. Откуда получаем что $p_{i_b | i_a} \in \set{0, 1}$, что и требовалось. 

	\noindent\fbox{\textit{Верхняя граница.}} Воспользуемся неравенством Гиббса (лемма \ref{lm:gibbs-ineq})
	\begin{multline*}
        - \H(\mathcal{B}  | \mathcal{A}) 
		= \sum_{i_a = 1}^{n_a} p_{i_a} \overbrace{\sum_{i_b = 1}^{n_b} p_{i_b | i_a} \log p_{i_b | i_a}}^{\geq \sum_{i_b = 1}^{n_b} p_{i_b | i_a} \log p_{i_b}}
		\geq \sum_{i_a = 1}^{n_a} p_{i_a} \sum_{i_b = 1}^{n_b} p_{i_b | i_a} \log p_{i_b} =\\
		= \sum_{i_a = 1}^{n_a} \sum_{i_b = 1}^{n_b}  \underbrace{p_{i_a} p_{i_b | i_a}}_{p_{i_b} p_{i_a | i_b}} \log p_{i_b}  
		= \sum_{i_b = 1}^{n_b} p_{i_b} \log p_{i_b} \underbrace{\sum_{i_a = 1}^{n_a} p_{i_a | i_b}}_{1}
		= -\H(\mathcal{B})
	\end{multline*}
	Откуда получаем что $\H(\mathcal{B} | \mathcal{A}) \leq \H(\mathcal{A})$. Рассмотрим случай равенства. Так как доказательство верхней оценки применяет неравенство Гиббса к $n_a$ суммам, случай равенства означает что \textit{для любого} $i_a = 1, \ldots, n_a$ выполнено равенство:
	\[
			\sum_{i_b = 1}^{n_b} p_{i_b | i_a} \log p_{i_b | i_a} = \sum_{i_b = 1}^{n_b} p_{i_b | i_a} \log p_{i_b}.
	\]
	Из этого как известно следует что $p_{i_b | i_a} = p_{i_b}$, что и означает что для любых $A \in \mathcal{A}, B \in \mathcal{B}$, события $A$ и $B$ независимы;
\end{proof}

\begin{example}[Случайная монета]
	Рассмотрим опять модель броска монетки. Пусть наугад выбирается монета: с вероятностью $\frac{1}{2}$ она честная, с вероятностью $\frac{1}{2}$ она фальшивая и выпадает всегда одной стороной --- для определенности скажем что решкой. Можем рассмотреть два опыта: первый состоит в наблюдении первого броска монеты и имеет два результата, $\mathcal{A}_1 = \set{O_1, P_1}$. Второй состоит в наблюдении второго броска монеты и также имеет два результата, $\mathcal{A}_2 = \set{O_2, P_2}$. Нетрудно вычислить вероятности событий: $\P(O_1) = \P(O_2) = \frac{1}{4}$, $\P(P_1) = \P(P_2) = \frac{3}{4}$ и значит:
	\[
		\H(\mathcal{A}_1) = \H(\mathcal{A}_2) = -\frac{3}{4}\log_2\frac{3}{4} - \frac{1}{4}\log_2\frac{1}{4}
	\]
	С другой стороны в среднем наблюдение первого броска снижает нашу неопределенность в вопросе фальшивости монеты --- как минимум, если при первом броске выпал орёл то монетка заведомо честная. Поэтому:
	\[
		\H(\mathcal{A}_2 | \mathcal{A}_1) = -\frac{3}{4}\left(\frac{3}{4}\log_2\frac{3}{4} + \frac{1}{4}\log_2\frac{1}{4}\right) -\frac{1}{4}\left(\frac{1}{2}\log_2\frac{1}{2} + \frac{1}{2}\log_2\frac{1}{2}\right)
	\]
	
\end{example}

\begin{definition}[Независимость опытов]
	Два опыта $\mathcal{A}$ и $\mathcal{B}$ называются независимыми, если любая пара результатов~$A \in \mathcal{A}$ и $B \in \mathcal{B}$ суть независимые события.
\end{definition}
\begin{remark}
	Таким образом $\H(\mathcal{B} | \mathcal{A}) = \H(\mathcal{B})$ тогда и только тогда, когда опыты $\mathcal{A}$ и $\mathcal{B}$ независимы.
\end{remark}
\begin{definition}
	Будем говорить что опыт $\mathcal{B}$ определяется опытом $\mathcal{A}$ если  для любых событий $A \in \mathcal{A}, B \in \mathcal{B}$, выполнено что $\P(B | A) \in \set{0, 1}$.
\end{definition}
\begin{remark}
	Таким образом $\H(\mathcal{B} | \mathcal{A}) = 0$ тогда и только тогда, когда опыт $\mathcal{A}$ определяет опыт $\mathcal{B}$.
\end{remark}
\begin{remark}
	Почему такое определение естественно? Оказывается что если опыт $\mathcal{B}$ определяется опытом $\mathcal{A}$, то для любого $A_{i_a}$ результата опыта $\mathcal{A}$ существует ровно один результат $B_{r(i_a)}$ опыта $\mathcal{B}$, такой что $\P(B_{r(i_a)} | A_{i_a}) = 1$; Это следует из того что:
\[
	\sum_{i_b = 1}^{n_b} \P(B_{i_b} | A_{i_a}) = 1
\]
Поэтому зная результат опыта $\mathcal{A}$ можно достоверно предсказать результат опыта $\mathcal{B}$.
\end{remark}
\begin{example}[Два броска монеты]
	Пусть \(\mathcal{A}_1 = \set{O_1, P_1}\) и \(\mathcal{A}_2 = \set{O_2, P_2}\) --- два опыта состоящие в броске монеты. Если броски независимы и монета честная, то:
\[
	\H(\mathcal{A}_1) = \H(\mathcal{A}_1 | \mathcal{A}_2) = 1 \text{ бит}, \quad \H(\mathcal{A}_2) = \H(\mathcal{A}_2 | \mathcal{A}_1) = 1 \text{ бит} .
\]
Если второй бросок полностью зависит от первого (например, всегда противоположен первому), то
\[
	\H(\mathcal{B} | \mathcal{A}) = \H(\mathcal{A} | \mathcal{B}) = 0 \text{ бит}.
\]
\end{example}

Аналогично тому как вводится понятие независимости в совокупности для событий\footnote{И для случайных величин}, можно ввести понятие независимых в совокупности опытов.
\begin{definition}[Независимость опытов в совокупности]
	Опыты $\mathcal{A}_1, \ldots \mathcal{A}_r$ называются независимыми в совокупности, если для любого поднабора $\mathcal{A}_{j_1}, \ldots, \mathcal{A}_{j_k}$ любые события $A_1 \in \mathcal{A}_{j_1}, \ldots A_{k} \in \mathcal{A}_{j_k}$ будут независимыми в совокупности.
\end{definition}
\begin{remark}
	Определение можно упростить: $\mathcal{A}_1, \ldots \mathcal{A}_r$ называются независимыми в совокупности, если для любого поднабора $\mathcal{A}_{j_1}, \ldots, \mathcal{A}_{j_k}$ и любых событий $A_1 \in \mathcal{A}_{j_1}, \ldots A_{k} \in \mathcal{A}_{j_k}$:
	\[
		\P(A_1 \cap \ldots \cap A_k) = \P(A_1) \cdot \ldots \cdot \P(A_k)
	\]
	Так как равенство выполнено для любых наборов событий $(A_1, \ldots, A_k)$ из разных опытов, то в частности выполнено для любого поднабора.
\end{remark}
\begin{example}
	Пусть честная монетка независимо бросается $r$ раз. Обозначим за $O_i$($P_i$), $i = 1, \ldots r$ событие \enquote{\textit{при $i$-ом броске выпал(а) орёл (решка)}}. Рассмотрим следующие опыты:
	\begin{align*}
		&\mathcal{A}_i = \set{O_i, P_i},\quad i = 1, \ldots, r \\
		&\mathcal{A}_0 = \set{T_0, T_1},\quad \text{$T_0$ --- число выпавших орлов чётно, $T_1$ --- нечетно}
	\end{align*}
	Тогда опыты $\mathcal{A}_1, \ldots, \mathcal{A}_r$ независимы в совокупности, а если добавить к ним $\mathcal{A}_0$, то независимость в совокупности пропадёт и останется только попарная независимость\footnote{Проверьте}.
\end{example}

\subsection{Совместная энтропия}

\begin{definition}[Совместная энтропия]
		Пусть \(p_{i_ai_b} = \P(A_{i_a} \cap B_{i_b})\). Совместная энтропия опытов \(\mathcal{A}\) и \(\mathcal{B}\) определяется как:
\[
	\H_m(\mathcal{A}, \mathcal{B}) = - \sum_{i_a=1}^{n_a} \sum_{i_b=1}^{n_b} \P(A_{i_a}, B_{i_b}) \cdot \I_m(A_{i_a}, B_{i_b}) = - \sum_{i_a=1}^{n_a} \sum_{i_b=1}^{n_b} p_{i_ai_b} \log_m p_{i_ai_b}.
\]
\end{definition}

Мы можем думать о совместной энтропии, как об энтропии опыта, состоящего в
одновременном проведении опытов~$\mathcal{A}$ и~$\mathcal{B}$. Формально это можно выразить следующим образом.
\begin{definition}[Произведение двух опытов]
Пусть имеются два опыта:
\[
	\mathcal{A} = \set{A_{i_a}}_{i = 1}^{n_a}, \quad \mathcal{B} = \set{B_{i_b}}_{i_b = 1}^{n_b},
\]
Их произведением называется опыт:
\[
	\mathcal{A} \land \mathcal{B} = \set{A_{i_a} \cap B_{i_b}  | \P(A_{i_a} \cap B_{i_b}) > 0}_{i_a=1,\dots,n_a}^{i_b=1,\dots,n_b}.
\]
\end{definition}
Тогда получим что $\H(\mathcal{A}, \mathcal{B}) = \H(\mathcal{A} \land \mathcal{B})$. Естественным образом можно теперь ввести совместную энтропию нескольких опытов:
\[
	\H(\mathcal{A}_1, \ldots, \mathcal{A}_r) = \H(\mathcal{A}_1 \land \ldots \land \mathcal{A}_r).
\]
\begin{example}[Случайная монета, продолжение - 1]
	Вернемся к модели, где выбор между настоящей и фальшивой монетой делается наугад. Два опыта: первый состоит в наблюдении того, какая была вытащена монета: $\mathcal{B} = \set{\text{Н}, \text{Ф}}$. Второй состоит в наблюдении первого броска монеты и также имеет два результата, $\mathcal{A}_1 = \set{O_1, P_1}$. Их произведение при этом будет состоять из трёх событий:
		\[
			\mathcal{A}_1 \land \mathcal{B} = \set{\text{Н} \cap O_1, \text{Ф} \cap P_1, \text{Н} \cap P_1}
		\]
		Поскольку при вытаскивании фальшивой монеты, орёл выпасть не может. Совместная энтропия при этом равна:
		\[
			\H(\mathcal{A}_1, \mathcal{B}) = - \frac{1}{4}\log_2\frac{1}{4} - \frac{1}{4}\log_2\frac{1}{4} -  \frac{1}{2}\log_2\frac{1}{2} = \text{1.5 бит}  
		\]
\end{example}

\begin{proposition}[Правило цепочки]
	\label{prop:entropy-chain-rule}
	Для двух случайных опытов \(\mathcal{A}\) и \(\mathcal{B}\) выполняется соотношение
	\[
		\H_m(\mathcal{A}, \mathcal{B}) = \H_m(\mathcal{A}) + \H(\mathcal{B} | \mathcal{A}) = \H_m(\mathcal{B}) + \H_m(\mathcal{A} | \mathcal{B}).
	\]
\end{proposition}
\begin{proof}
Не умаляя общности $m = 2$. По определению совместной энтропии:
\[
	\H(\mathcal{A}, \mathcal{B})
	= - \sum_{i_a,i_b} p_{i_a i_b} \log p_{i_a i_b} 
	= - \sum_{i_a,i_b} p_{i_a i_b} \log (p_{i_a} p_{i_b | i_a})
	= - \sum_{i_a} p_{i_a} \log p_{i_a} - \sum_{i_a} p_i \sum_{i_b} p_{i_b | i_a} \log p_{i_b |i_a} 
	= \H(\mathcal{A}) + \H(\mathcal{B} | \mathcal{A}).
\]
Симметрично, меняя местами \(\mathcal{A}\) и \(\mathcal{B}\), получаем второе равенство.
\end{proof}
\begin{example}[Случайная монета, продолжение - 2]
	Можем убедиться, рассматривая модель, где выбор между настоящей и фальшивой монетой делается наугад. Как и ранее, рассматриваем два опыта: первый состоит в наблюдении того, какая была вытащена монета: $\mathcal{B} = \set{\text{Н}, \text{Ф}}$. Второй состоит в наблюдении первого броска монеты и также имеет два результата, $\mathcal{A}_1 = \set{O_1, P_1}$. 

	По примеру ранее $\H(\mathcal{A}_1 | \mathcal{B}) = 1.5\text{ бит}$. Энтропия $\H(\mathcal{B}) = 1 \text{ бит}$. Посчитаем:
	\[
		\H(\mathcal{A}_1 | \mathcal{B}) = - \P(\text{Н}) \cdot \underbrace{\big[\P(O_1 | \text{Н})\log\P(O_1 | \text{Н}) + \P(P_1 | \text{Н})\log\P(P_1 | \text{Н})\big]}_{1 \text{ бит}} - \P(\text{Ф}) \cdot \underbrace{\P(P_1 | \text{Ф})\log\P(P_1 | \text{Ф})}_{0 \text{ бит}} = \frac{1}{2} \cdot 1 + \frac{1}{2} \cdot 0 = 0.5 \text{ бит}
	\]
	Все вычисления сошлись.
\end{example}
\begin{corollary}
	\label{corollary:joint-entropy-bound}
    Для любых двух опытов:
    \[
		\max\set{\H(\mathcal{A}), \H(\mathcal{B})} \leq \H(\mathcal{A}, \mathcal{B}) \leq \H(\mathcal{A}) + \H(\mathcal{B})
    \]
	Причем
	\begin{itemize}[compact]
		\item Равенство $\H(\mathcal{A}) = \H(\mathcal{A}, \mathcal{B})$ достигается тогда и только тогда, когда опыт $\mathcal{B}$ определяется опытом $\mathcal{A}$.
		\item Равенство $\H(\mathcal{A}, \mathcal{B}) = \H(\mathcal{A}) + \H(\mathcal{B})$ достигается тогда и только тогда, когда опыты $\mathcal{A}$ и $\mathcal{B}$ независимы.
	\end{itemize}
\end{corollary}
\begin{proof}
	Запишем правило цепочки (предложение \ref{prop:entropy-chain-rule}) и применим к нему с двух сторон оценки на условную энтропию (предложение \ref{prop:conditional-entropy-estimates})
	\begin{align*}
		& \H(\mathcal{A}, \mathcal{B}) = \H(\mathcal{A}) + \H(\mathcal{B} | \mathcal{A}) \geq \H(\mathcal{A})\\
		&\H(\mathcal{A}, \mathcal{B}) = \H(\mathcal{A}) + \H(\mathcal{B} | \mathcal{A}) \leq \H(\mathcal{A}) + \H(\mathcal{B})
	\end{align*}
	Случаи равенства разбираются исходя из случаев равенства оценок в предложении \ref{prop:conditional-entropy-estimates}.
\end{proof}
\begin{Theorem}[О значениях совместной энтропии]
    Для любых опытов $\mathcal{A}_1, \ldots, \mathcal{A}_{r}$:
	\[
		\max_{j = 1,\ldots,r} \H_m(\mathcal{A}_j) \leq \H_m(\mathcal{A}_1, \ldots \mathcal{A}_r) \leq \sum_{j = 1}^{r}\H_m(\mathcal{A}_j)
	\]
	Причем
	\begin{itemize}[compact]
		\item Равенство $\H_m(\mathcal{A}_1, \ldots \mathcal{A}_r) = \max \H_m(\mathcal{A}_j)$ достигается тогда и только тогда, когда один из опытов $\mathcal{A}_{k}$ определяет любой другой опыт $\mathcal{A}_{j}, j \neq k$.
		\item Равенство $\H_m(\mathcal{A}_1, \ldots \mathcal{A}_r) = \sum \H_m(\mathcal{A}_j)$ достигается тогда и только тогда, когда опыты $\mathcal{A}_1, \ldots, \mathcal{A}_{r}$ независимы в совокупности.
	\end{itemize}
\end{Theorem}
\begin{proof}
	Не умаляя общности $m = 2$. Индукцией по $r$. Базовый случай $r = 2$ уже доказан в следствии  \ref{corollary:joint-entropy-bound}. Начнем с самих неравенств при $r \geq 3$. Имеем:
	\begin{align*}
		& \H(\mathcal{A}_1, \ldots \mathcal{A}_r)
			= \H(\mathcal{A}_1,  \mathcal{A}_2 \land \ldots \land \mathcal{A}_r) 
		 \geq \max\set{\H(\mathcal{A}_1), \H(\mathcal{A}_2 \land \ldots \land \mathcal{A}_r)}
		    = \max\set{\H(\mathcal{A}_1), \H(\mathcal{A}_2, \ldots, \mathcal{A}_r)}
		\underset{\ast}{\geq} \max_{j = 1,\ldots,r} \H(\mathcal{A}_j) \\
		& \H(\mathcal{A}_1, \ldots \mathcal{A}_r) 
			= \H(\mathcal{A}_1,  \mathcal{A}_2 \land \ldots \land \mathcal{A}_r) 
		 \leq \H(\mathcal{A}_1) + \H(\mathcal{A}_2 \land \ldots \land \mathcal{A}_r) 
	 	 	= \H(\mathcal{A}_1) + \H(\mathcal{A}_2, \ldots, \mathcal{A}_r) 
			\underset{\ast}{\leq} \sum_{j = 1}^{r}\H(\mathcal{A}_j),
	\end{align*}
	где переходы $\ast$ сделаны по предположению индукции. Разберем случай равенства.

	\noindent \textbf{Равенство максимуму.} Не умаляя общности пусть
	\[
	\H(\mathcal{A}_1, \ldots \mathcal{A}_r) = \H(\mathcal{A}_1)
	\]
	Тогда, так как \(\H(\mathcal{A}_1, \ldots \mathcal{A}_r)= \H(\mathcal{A}_1,  \mathcal{A}_2 \land \ldots \land \mathcal{A}_r)\),	получаем что опыт $\mathcal{A}_1$ полностью определяет опыт $\mathcal{A}_2 \land \ldots \land \mathcal{A}_r$. Формально это означает, что для любого набора событий $A_1 \in \mathcal{A}_1, \ldots, A_r \in \mathcal{A}_r$:
	\[
		\P(A_2 \cap \ldots \cap A_r | A_1) \in \set{0, 1}
	\]
	Покажем что $\P(A_2 | A_1) \in \set{0,1}$: распишем:
	\[
		\P(A_2 | A_1) = \sum_{A_3 \in \mathcal{A}_3} \cdots \sum_{A_r \in \mathcal{A}_r} \P(A_2 \cap \ldots \cap A_r | A_1) 
	\]
	Каждое слагаемое в правой части это либо 0, либо 1. С другой стороны, поскольку условная вероятность лежит в отрезке $[0; 1]$, получаем что вся сумма принимает значение или 0, или 1, что и требовалось доказать. Аналогично получаем что $\P(A_j | A_1) \in \set{0,1}$ при $j \neq 1$. В другую сторону случай равенства следует из того что, если опыт $\mathcal{A}_1$ определяет опыты $\mathcal{A}_2$ и $\mathcal{A}_3$, то определяет и опыт $\mathcal{A}_2 \land \mathcal{A}_3$, поскольку пересечение событий вероятностей 0 или 1, само есть событие вероятности 0 или 1.

	\noindent \textbf{Равенство сумме.} Имеем:
	\[
		\H(\mathcal{A}_1, \ldots, \mathcal{A}_r) = \sum_{j = 1}^{r} \H(\mathcal{A}_j)
	\]
	Тогда, так как \(\H(\mathcal{A}_1, \ldots \mathcal{A}_r)= \H(\mathcal{A}_1, \mathcal{A}_2 \land \ldots \land \mathcal{A}_r)\) имеем:
	\begin{enumerate}[compact]
		\item\label{proof:th-joint-entropy-bound-induction-corollary-1} Опыты $\mathcal{A}_1$ и $\mathcal{A}_2 \land \ldots \land \mathcal{A}_r$ независимы;
		\item \label{proof:th-joint-entropy-bound-induction-corollary-2} $\H(\mathcal{A}_2 \land \ldots \land \mathcal{A}_r) = \H(\mathcal{A}_2) + \ldots +\H(\mathcal{A}_r)$ 
	\end{enumerate}
	Хотим проверить что для любого поднабора $\mathcal{A}_{j_1}, \ldots, \mathcal{A}_{j_k}$ и любых событий $A_1 \in \mathcal{A}_{j_1}, \ldots, \mathcal{A}_{j_k}$ выполнено равенство
	\begin{equation}
		\label{eq:independence-eq}
		\P(A_1 \cap \ldots \cap A_k) = \P(A_1) \cdot \ldots \cdot \P(A_k)
	\end{equation}

	Применяя индукционное предположение к пункту \ref{proof:th-joint-entropy-bound-induction-corollary-2}, получаем что опыты $\mathcal{A}_2, \ldots, \mathcal{A}_r$ независимы в совокупности. Таким образом, равенство \eqref{eq:independence-eq} выполнено, когда среди набора $\mathcal{A}_{j_1}, \ldots, \mathcal{A}_{j_k}$ нет опыта $\mathcal{A}_1$.  Тогда, чтобы доказать независимость в совокупности опытов $\mathcal{A}_1, \ldots, \mathcal{A}_r$ нужно показать равенство \eqref{eq:independence-eq} для поднаборов $\mathcal{A}_{j_1}, \ldots, \mathcal{A}_{j_k}$ с $j_1 = 1$ и произвольных  $A_1 \in \mathcal{A}_{j_1}, \ldots,  A_{k} \in \mathcal{A}_{j_k}$.

	Обозначим за $t_1, \ldots, t_{r-k}$ индексы не вошедшие в набор $j_1, \ldots, j_k$, т.е. $\set{t_1, \ldots, t_{r-k}} = \set{1, \ldots, r} \setminus \set{j_1, \ldots, j_k}$; Имеем по пункту \ref{proof:th-joint-entropy-bound-induction-corollary-1}:
	\begin{multline*}
		\P(A_1 \cap \ldots \cap A_k)
		= \sum_{A_{k+1} \in \mathcal{A}_{t_1}} \cdots  \sum_{A_{r} \in \mathcal{A}_{t_{r-k}}} \underbrace{\P(A_1 \cap \ldots A_k \cap A_{k+1} \ldots A_{r})}_{\in \mathcal{A}_1 \land \ldots \land \mathcal{A}_r} = \\
		= \sum_{A_{k+1} \in \mathcal{A}_{t_1}} {\cdots} \sum_{A_{r} \in \mathcal{A}_{t_{r-k}}} \P(A_1) \cdot \P(A_2 \cap \ldots A_k \cap A_{k+1} \ldots A_{r})  
		= \P(A_1) \cdot \smashoperator[l]{\sum_{A_{k+1} \in \mathcal{A}_{t_1}}} \cdots \sum_{A_{r} \in \mathcal{A}_{t_{r-k}}} \P(A_2 \cap \ldots A_k \cap A_{k+1} \ldots A_{r}) = \\ 
		 = \P(A_1) \cdot \P(A_2 \cap \ldots A_k) 
		 = \P(A_1) \cdot \P(A_2) \cdot \ldots \cdot \P(A_k)
	 \end{multline*}
	 Что и требовалось доказать. В обратную сторону случай равенства напрямую следует из \ref{corollary:joint-entropy-bound}.
\end{proof}

\subsection*{Приложение. О независимых опытах, $\sigma$-алгебрах и энтропии}

Доказательство теоремы выглядит довольно хитрым и возникает соблазн как-то его упростить. Можно; но для этого придется сделать язык чуть более абстрактным и доказать пару предварительных результатов.

\begin{remark}
	Это приложение --- скорее черновик того, как можно развивать мысль. Многие переходы намерено расписаны не очень подробно или даже туманно, дабы дать читателю некоторую творческую свободу. Можно расценивать это приложение как руководство по тому, как не стоит записывать доказательства.
\end{remark}


Для начала, дадим теоретико-множественную трактовку тому, что один опыт определяет другой.
\begin{definition*}[Эквивалентность опытов \(\operatorname{mod} 0\)]
	Опыты \(\mathcal{A}\) и \(\mathcal{B}\) называются равными \(\operatorname{mod} 0\), если для любого результата \(A\in\mathcal{A}\) существует результат \(B\in\mathcal{B}\) такой, что
    \[
		\P(A \mathbin{\triangle} B) = 0,
    \]
	где \(A \mathbin{\triangle} B\) --- симметрическая разность множеств. Записывается как \(\mathcal{A}= \mathcal{B}\pmod 0\).
\end{definition*}
\begin{remark}
	$\cdot = \cdot\pmod0$ это отношение эквивалентности.
\end{remark}
\begin{proposition*}
    Опыт \(\mathcal{B}\) определяется опытом \(\mathcal{A}\) тогда и только тогда, когда:
    \[
        \mathcal{A} = \mathcal{A}\land\mathcal{B}\pmod 0 .
    \]
\end{proposition*}
\begin{proof}
	Пусть опыт \(\mathcal{B}\) определяется опытом \(\mathcal{A}\). Так как $\mathcal{B}$ определяется $\mathcal{A}$, для любого $A_{i_a} \in \mathcal{A}$ существует единственное $B_{i_b} \in \mathcal{B}$ такое что 
	\[
		\P(B_{i_b} | A_{i_a}) = 1
	\]
	Иначе говоря $\P(B_{i_b} \cap A_{i_a}) = \P(A_{i_a})$. Значит, по аддитивности вероятности, $\P((A_{i_a} \cap B_{i_b}) \mathbin{\triangle} A_{i_a}) = 0$. Отсюда прямым образом следует $\mathcal{A} = \mathcal{A}\land\mathcal{B}\pmod 0$.  

	Теперь обратно. Если $\mathcal{A} = \mathcal{A}\land\mathcal{B} \pmod 0$, то любое событие $B \in \mathcal{B}$ представимо, с точностью до множества меры 0, как объединение нескольких множеств $A_1, \ldots A_k \in \mathcal{A}$, а значит все условные вероятности вырождены.
\end{proof}

\begin{remark}
	Интуиция тут может быть следующая. Каждый опыт задает некоторое разбиение пространства элементарных исходов $\Omega$. Опыт $\mathcal{A}$ определяет $\mathcal{B}$, если опыт $\mathcal{A}$ как разбиение $\Omega$ является измельчением разбиения $\mathcal{B}$ (с точностью до множеств меры 0).
\end{remark}

Однако как подсказывает заголовок при как подсказывает заголовок приложения, речь в какой-то момент должна зайти о $\sigma$-алгебрах. Действительно, формулировки о том что две (или больше) системы событий независимы или определяют друг друга в некотором смысле выглядят кустарно. Оказывается, если вместо полной системы событий $\mathcal{A}$ рассматривать порождённую ей $\sigma$-алгебру $\sigma(\mathcal{A})$ мы придем к более естественным формулировкам.

\begin{definition*}
	Для двух $\sigma$‑алгебр \(\mathcal{F} \subset \mathcal{H}\) и \(\mathcal{G} \subset \mathcal{H}\) на одном вероятностном пространстве \((\Omega,\mathcal{H},\P)\),  их совместная $\sigma$-алгебра есть
    \[
        \mathcal{F}\lor\mathcal{G} \eqcolon \sigma(\mathcal{F}\cup\mathcal{G}),
    \]
	то есть наименьшая $\sigma$‑алгебра, содержащая $\mathcal{F}$ и $\mathcal{G}$.
\end{definition*}
\begin{proposition*}
    Пусть \(\mathcal{A},\mathcal{B}\) --- полные системы событий. Тогда
    \[
        \sigma(\mathcal{A}) \lor \sigma(\mathcal{B}) = \sigma(\mathcal{A}\land\mathcal{B}),
    \]
\end{proposition*}
\begin{proof}
    С одной стороны, каждый элемент \(A\cap B\) принадлежит \(\sigma(\mathcal{A})\) и \(\sigma(\mathcal{B})\), следовательно,
    \[
        \sigma(\mathcal{A}\land\mathcal{B})\subseteq \sigma(\mathcal{A})\lor\sigma(\mathcal{B}).
    \]
    С другой стороны, любые события из \(\mathcal{A}\) и \(\mathcal{B}\) могут быть получены как объединения пересечений \(A\cap B\). Поэтому есть включение \(\sigma(\mathcal{A})\cup\sigma(\mathcal{B})\subseteq\sigma(\mathcal{A}\land\mathcal{B})\), а значит и их порождённая $\sigma$-алгебра \(\sigma(\mathcal{A})\lor\sigma(\mathcal{B})\) содержится в \(\sigma(\mathcal{A}\land\mathcal{B})\). Получаем равенство.
\end{proof}

Для $\sigma$-алгебр аналогично полным системам событий можно ввести понятие равенство $\operatorname{mod} 0$ и включения $\operatorname{mod} 0$ (последнее означает, что каждый элемент из более грубой $\sigma$-алгебры с точностью до множества вероятности 0 содержится в более тонкой $\sigma$-алгебре).

Оказывается что верно следующее:
\begin{proposition*}
	Опыт $\mathcal{B}$ определяется опытом $\mathcal{A}$ тогда и только тогда, когда $\sigma(\mathcal{B}) \subseteq \sigma(\mathcal{A}) \pmod 0$.
\end{proposition*}
\begin{proof}
	Следует из ранее доказанного.
\end{proof}


Теперь надо разобраться с независимостью опытов. Для $\sigma$-алегбр понятие независимости вводится следующим образом:

\begin{definition*}[Независимость сигма‑алгебр]
	Сигма‑алгебры \(\mathcal{F}_1 \subset \mathcal{H}, \ldots, \mathcal{F}_r \subset \mathcal{H}\)  на одном вероятностном пространстве \((\Omega,\mathcal{H},\P)\) называются независимыми в совокупности, если для всех \(F_1 \in\mathcal{F}_1, \ldots, F_r \in \mathcal{F}_r\):
    \[
        \P(F_1 \cap \ldots \cap F_r)=\P(F_1) \ldots \P(F_r).
    \]
\end{definition*}
\begin{remark}
	Полагая некоторые из $F_i$ равными $\Omega$, получаем что события $F_1, \ldots, F_r$ будут независимы в совокупности.
\end{remark}

\begin{lemma*}
    Пусть \(E\) --- событие, \(\mathcal{A}\) --- некоторый опыт, и \(E\) независимо от любого \(A\in\mathcal{A}\). Тогда \(E\) независимо от любого события \(C \in \sigma(\mathcal{A})\).
\end{lemma*}
\begin{proof}
	Каждое \(C \in \sigma(\mathcal{A})\) представимо как объединение некоторых множеств $A_{j_1}, \ldots, A_{j_k} \in \mathcal{A}$. Распишем
	\[
		\P(E \cap C) = \P(E \cap [A_{j_1} \cup \ldots A_{j_k}]) = \sum_{i = 1}^{k} \P(E \cap A_{j_i}) = \P(E) \sum_{i = 1}^{k} \P(A_{j_i}) = \P(E)\P(C)
	\]
\end{proof}
\begin{corollary*}
	Опыты $\mathcal{A}$ и $\mathcal{B}$ независимы тогда и только тогда, когда независимы $\sigma(\mathcal{A})$ и $\sigma(\mathcal{B})$.
\end{corollary*}
\begin{proof}
	Из независимости $\sigma$-алгебр независимость опытов следует по определению. В другую сторону. Пусть теперь $A \in \sigma(\mathcal{A}), B \in \sigma(\mathcal{B})$. Поскольку опыты $\mathcal{A}$ и $\mathcal{B}$ независимы, событие $B \in \sigma(\mathcal{B})$ и событие $A' \in \mathcal{A}$ независимы для любого события $A'$ в силу леммы выше. Тогда применяя лемму теперь уже к событию $B$ получаем что $B$ независимо с любым $A \in \sigma(\mathcal{A})$.
\end{proof}
\begin{remark}
	Обобщение на случай нескольких независимых в совокупности опытов доказывается mutatis mutandis.
\end{remark}
\begin{proposition*}
	Пусть $\mathcal{F}_1$, $\mathcal{F}_2$ --- две независимые $\sigma$-алгебры на \((\Omega,\mathcal{H},\P)\), $\mathcal{G} \subset \mathcal{F}_1$. Тогда $\mathcal{G}$ и $\mathcal{F}_2$ независимы.
\end{proposition*}
\begin{proof}
	Следует напрямую из определения.
\end{proof}
\bigskip

\noindent\textbf{Упрощённое доказательство теоремы о совместной энтропии.}

\begin{enumerate}[label=\arabic*., leftmargin=*, nosep]
    \item \textbf{Равенство с максимумом.}
          Предположим
          \[
              \H(\mathcal{A}_{1},\dots,\mathcal{A}_{r})=\H(\mathcal{A}_{1}).
          \]
          По определению совместной энтропии
          \[
              \H(\mathcal{A}_{1},\dots,\mathcal{A}_{r})
              =\H\bigl(\mathcal{A}_{1}\land(\mathcal{A}_{2}\land\dots\land\mathcal{A}_{r})\bigr).
          \]
          Следовательно,
          \[
              \H(\mathcal{A}_{1})=\H\bigl(\mathcal{A}_{1}\land(\mathcal{A}_{2}\land\dots\land\mathcal{A}_{r})\bigr),
          \]
          а значит \(\sigma(\mathcal{A}_{2}\land\dots\land\mathcal{A}_{r})\subseteq\sigma(\mathcal{A}_{1})\pmod 0\). Поскольку
          \(\sigma(\mathcal{A}_{j})\subseteq\sigma(\mathcal{A}_{2}\land\dots\land\mathcal{A}_{r})\) для любого \(j\ge2\), получаем
          \[
              \sigma(\mathcal{A}_{j})\subseteq\sigma(\mathcal{A}_{1})\pmod 0,\qquad j=2,\dots,r.
          \]
          Это эквивалентно тому, что каждый опыт \(\mathcal{A}_{j}\) определяется \(\mathcal{A}_{1}\), что и требовалось.

    \item \textbf{Равенство с суммой.}
          Предположим
          \[
              \H(\mathcal{A}_{1},\dots,\mathcal{A}_{r})
              =\sum_{j=1}^{r}\H(\mathcal{A}_{j}).
          \]
          По уже доказанному случаю \(r=2\) получаем
          \[
              \sigma(\mathcal{A}_{1})\ \text{независима от}\ \sigma(\mathcal{A}_{2}\land\dots\land\mathcal{A}_{r}),
          \]
          а также
          \[
              \H(\mathcal{A}_{2}\land\dots\land\mathcal{A}_{r})
              =\sum_{j=2}^{r}\H(\mathcal{A}_{j}),
          \]
          что по индукционному предположению означает независимость сигма‑алгебр
          \(\sigma(\mathcal{A}_{2}),\dots,\sigma(\mathcal{A}_{r})\) в совокупности.
          Теперь, используя независимость \(\sigma(\mathcal{A}_{1})\) от их объединения
          \(\sigma(\mathcal{A}_{2}\lor\dots\lor\mathcal{A}_{r})\) и факт
          \(\sigma(\mathcal{A}_{2}\lor\dots\lor\mathcal{A}_{r})
           =\sigma(\mathcal{A}_{2}) \land\dots\land \sigma(\mathcal{A}_{r})\),
          получаем независимость всех \(\sigma(\mathcal{A}_{j})\), \(j=1,\dots,r\) (поскольку это подалгебры $\sigma(\mathcal{A}_{2}) \land\dots\land \sigma(\mathcal{A}_{r})$).
          Это эквивалентно независимости самих опытов \(\mathcal{A}_{1},\dots,\mathcal{A}_{r}\).
\end{enumerate}
